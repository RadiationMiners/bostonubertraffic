{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CSV file containing cleaned Uber data can be found here: \n",
    "\n",
    "https://drive.google.com/file/d/1pWGv84eaEZF495H7HVwDOFHnLj66-Nbh/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the local csv files into dataframes.**\n",
    "\n",
    "**\"bus.csv\" and \"times.csv\" should be in the GitHub repo, but uber.csv is not. Find that here: https://drive.google.com/file/d/1QaT4NrrkulKCc1OKrVxXukOJdUp8XiC8/view?usp=sharing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucaslyon/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "uber = pd.read_csv('uber.csv', index_col = 0)\n",
    "busDf = pd.read_csv('bus.csv', index_col = 0)\n",
    "timesDf = pd.read_csv(\"times.csv\", names=[\"start\", \"stop\", \"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a list of unique routes from the busDf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = busDf.ROUTE_OR_LINE.unique()\n",
    "lines.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort the Uber dataframe by source and then destination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uber = uber.sort_values(['sourceid', 'dstid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to find the days where every line was slower than 80% of the average.**\n",
    "\n",
    "If we just look at days where the lines were slower than 100% of the average, we get way too many days to look at. We need to be more strict with out analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lateDays(lines, busDf):\n",
    "    \n",
    "    linesSlowerThanAvg = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        #get the piece of the dataframe that has data for each line\n",
    "        thisLine = busDf.loc[busDf['ROUTE_OR_LINE'] == line]\n",
    "        \n",
    "        averageOnTime = ((thisLine['PERCENT_ONTIME']).mean())*0.8\n",
    "        \n",
    "        slowerThanAverage = thisLine.loc[(thisLine['PERCENT_ONTIME'] < averageOnTime)]\n",
    "        \n",
    "        datesSlowerThanAverage = slowerThanAverage['SERVICE_DATE']\n",
    "        \n",
    "        percentOnTime = slowerThanAverage['PERCENT_ONTIME']\n",
    "        \n",
    "        listDates = datesSlowerThanAverage.tolist()\n",
    "        \n",
    "        listPercents = percentOnTime.tolist()\n",
    "        \n",
    "        concatenated = [] \n",
    "        \n",
    "        for ii in range(len(listDates)):\n",
    "            concatenated.append((listDates[ii], listPercents[ii]))\n",
    "        \n",
    "        linesSlowerThanAvg[line] = concatenated\n",
    "        \n",
    "    return linesSlowerThanAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a dictionary of days that each line was pretty late, including what percent of buses were on-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysSlowerThanAvg = lateDays(lines, busDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 229\n",
      "171 233\n",
      "225 64\n",
      "201 199\n",
      "230 234\n",
      "60 156\n",
      "62 93\n",
      "65 86\n",
      "78 168\n",
      "104 174\n",
      "215 302\n",
      "26 261\n",
      "411 279\n",
      "442 96\n",
      "449 392\n",
      "88 80\n",
      "SL5 0\n",
      "4 306\n",
      "132 109\n",
      "170 352\n",
      "424 306\n",
      "426 163\n",
      "434 172\n",
      "7 23\n",
      "106 194\n",
      "35 99\n",
      "43 194\n",
      "44 99\n",
      "51 152\n",
      "57A 81\n",
      "76 124\n",
      "CT3 268\n",
      "SL1 0\n",
      "111 0\n",
      "114 314\n",
      "9 33\n",
      "116 11\n",
      "222 144\n",
      "236 276\n",
      "326 231\n",
      "39 0\n",
      "435 252\n",
      "119 214\n",
      "21 63\n",
      "216 39\n",
      "428 321\n",
      "451 169\n",
      "456 126\n",
      "459 236\n",
      "503 172\n",
      "80 188\n",
      "87 156\n",
      "SL2 5\n",
      "8 247\n",
      "137 329\n",
      "14 206\n",
      "220 116\n",
      "24 187\n",
      "351 260\n",
      "554 197\n",
      "91 325\n",
      "99 285\n",
      "501 66\n",
      "221 277\n",
      "431 71\n",
      "448 304\n",
      "553 202\n",
      "69 62\n",
      "92 151\n",
      "455 204\n",
      "68 159\n",
      "746 24\n",
      "75 124\n",
      "5 296\n",
      "11 93\n",
      "112 288\n",
      "16 206\n",
      "22 0\n",
      "34 63\n",
      "430 205\n",
      "502 82\n",
      "89 136\n",
      "90 229\n",
      "109 170\n",
      "192 194\n",
      "194 115\n",
      "214 96\n",
      "240 242\n",
      "245 195\n",
      "441 109\n",
      "55 156\n",
      "77 0\n",
      "117 9\n",
      "131 221\n",
      "17 201\n",
      "211 228\n",
      "350 133\n",
      "36 160\n",
      "436 109\n",
      "10 98\n",
      "105 343\n",
      "108 215\n",
      "23 0\n",
      "29 289\n",
      "31 50\n",
      "32 0\n",
      "352 225\n",
      "45 111\n",
      "47 159\n",
      "93 108\n",
      "210 287\n",
      "465 144\n",
      "505 123\n",
      "71 1\n",
      "79 174\n",
      "59 228\n",
      "72 81\n",
      "136 253\n",
      "504 210\n",
      "558 295\n",
      "70 116\n",
      "86 93\n",
      "202 294\n",
      "439 163\n",
      "50 208\n",
      "57 0\n",
      "84 266\n",
      "19 182\n",
      "30 224\n",
      "85 162\n",
      "CT1 270\n",
      "101 51\n",
      "217 240\n",
      "33 183\n",
      "450 190\n",
      "212 309\n",
      "354 162\n",
      "70A 206\n",
      "73 2\n",
      "94 164\n",
      "95 247\n",
      "74 180\n",
      "429 143\n",
      "110 185\n",
      "40 275\n",
      "556 219\n",
      "97 318\n",
      "CT2 287\n",
      "1 6\n",
      "27 273\n",
      "37 127\n",
      "64 164\n",
      "18 247\n",
      "67 127\n",
      "SL4 8\n",
      "9703 150\n",
      "120 266\n",
      "134 159\n",
      "15 2\n",
      "34E 201\n",
      "608 4\n",
      "83 157\n",
      "193 248\n",
      "38 192\n",
      "191 229\n",
      "325 310\n",
      "41 319\n",
      "42 185\n",
      "96 106\n",
      "28 0\n",
      "66 0\n",
      "238 222\n",
      "9701 91\n",
      "121 122\n",
      "9702 98\n",
      "52 220\n",
      "195 198\n",
      "72/75 32\n",
      "62/76 15\n",
      "713 0\n"
     ]
    }
   ],
   "source": [
    "#checking how many values each key has\n",
    "for key, value in daysSlowerThanAvg.items():\n",
    "    #print value\n",
    "    print(key, len([item for item in value if item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('11/24/16 0:00', 0.545144804088586),\n",
       " ('12/25/16 0:00', 0.5582978723404255),\n",
       " ('4/28/17 0:00', 0.5570175438596491),\n",
       " ('5/25/17 0:00', 0.5602836879432624),\n",
       " ('10/8/17 0:00', 0.5149384885764499),\n",
       " ('12/25/17 0:00', 0.5618789521228545)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daysSlowerThanAvg['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to determine average travel times to and from each census tract in the Uber dataset.**\n",
    "\n",
    "Output of this function has been saved in \"times.csv\" and the timesDf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def averageTravelTimes(sources, dests, dataset):\n",
    "    fromtotimes = {}\n",
    "    counter = 0\n",
    "    for source in sources:\n",
    "        sliced = dataset.loc[(dataset['sourceid'] == source)]\n",
    "        for dest in dests:\n",
    "            furthersliced = sliced.loc[(sliced['dstid'] == dest)]\n",
    "            if len(furthersliced.index != 0):\n",
    "                mean = furthersliced['geometric_mean_travel_time'].mean()\n",
    "                fromtotimes[(source, dest)] = mean\n",
    "                counter+=1\n",
    "                if (counter % 5000) == 0:\n",
    "                    print(source, dest, mean)\n",
    "    return fromtotimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#times = averageTravelTimes(sources, dests, uber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#timesSeries.index.name = 'To From Pair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#timesSeries.reset_index()\n",
    "#timesSeries.to_csv('times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timesDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To compare Uber and MBTA bus lines, we need to know what census tracts each line goes through. Here's the process:**\n",
    "\n",
    "1. Find a map with census tracts. I use https://worldmap.harvard.edu/maps/3948. Uncheck everything on the left, and then under \"Boundaries\" check \"Boston's Census Tracts\".\n",
    "\n",
    "2. Use the MBTA's website to get a map of the line route. https://www.mbta.com/schedules/bus\n",
    "\n",
    "3. Click on areas of the Harvard Map that the line you're working on goes through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones_100 = [\"837\", \"588\", \"838\", \"836\", \"203\", \"587\"]\n",
    "zones_7 = [\"885\", \"883\", \"530\", \"425\", \"501\"]\n",
    "zones_1 = [\"806\", \"804\", \"711\", \"709\", \"708\", \"10402\", \"10401\", \"10101\", ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
