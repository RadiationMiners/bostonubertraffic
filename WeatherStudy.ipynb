{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To What Extent Does Weather Impact Percent On Time of Buses?\n",
    "   This notebook is intended to be used to take MTBA bus data and weather data collected by a NOAA station in boston to determine if weather has a measurable impact on the percent of buses that are on time. The MTBA data set includes for its bus entries if it's reccord is from peak hours or off peak as well as number of busses on time that day for that route and number of total busses that ran on that route that day. The weather data includes a number of attributes not as useful, but does include inches of snow, rain, as well as Average Temperature, Max Temperature, and Min Temperature. Both datasets entries have dates, which can and will be joined on to get the data sets together. After which the data will be reorganized for use by a machine learning algorithm or two. The goal is to find an algorithm that will produce a model with good performance, and then look at the weights of different weather to come to a conclusion on how impactful weather is for percent on time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These first few cells are for combining the weather and bus data\n",
    "I ended up joining the two sets on date and then reducing the columns. The bus data had two columns that could be useful for this which were route number and peak or off peak. I initially removed route number but might try to bring it back in. The peak or off peak attribute I figured would be interesting but discovered it was making all of the models perform very poorly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>4/20/2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>4/21/2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>4/22/2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>4/23/2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  PRCP  SNOW  TAVG  TMAX  TMIN\n",
       "838  4/20/2018   0.0   0.0  44.0  53.0  36.0\n",
       "839  4/21/2018   0.0   0.0  47.0  59.0  39.0\n",
       "840  4/22/2018   0.0   0.0  51.0  62.0  42.0\n",
       "841  4/23/2018   0.0   0.0  51.0  58.0  43.0\n",
       "842        NaN   NaN   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus = pd.read_csv(\"bus1.csv\")\n",
    "weath = pd.read_csv(\"weather_trimmed.csv\")\n",
    "bus.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above reads in the two datasets, already prepared to be joined, below joins data sets and outputs for further trimming and re-ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERVICE_DATE</th>\n",
       "      <th>PEAK_OFFPEAK_IND</th>\n",
       "      <th>ROUTE_TYPE</th>\n",
       "      <th>OTP_NUMERATOR</th>\n",
       "      <th>OTP_DENOMINATOR</th>\n",
       "      <th>% on time</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202309</th>\n",
       "      <td>3/27/2018</td>\n",
       "      <td>Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...</td>\n",
       "      <td>KBR</td>\n",
       "      <td>630</td>\n",
       "      <td>728</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202310</th>\n",
       "      <td>3/27/2018</td>\n",
       "      <td>Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...</td>\n",
       "      <td>OTH</td>\n",
       "      <td>176</td>\n",
       "      <td>220</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202311</th>\n",
       "      <td>3/27/2018</td>\n",
       "      <td>Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...</td>\n",
       "      <td>OTH</td>\n",
       "      <td>223</td>\n",
       "      <td>310</td>\n",
       "      <td>0.719355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202312</th>\n",
       "      <td>3/27/2018</td>\n",
       "      <td>Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...</td>\n",
       "      <td>OTH</td>\n",
       "      <td>106</td>\n",
       "      <td>184</td>\n",
       "      <td>0.576087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202313</th>\n",
       "      <td>3/27/2018</td>\n",
       "      <td>Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...</td>\n",
       "      <td>OTH</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SERVICE_DATE                                   PEAK_OFFPEAK_IND  \\\n",
       "202309    3/27/2018  Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...   \n",
       "202310    3/27/2018  Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...   \n",
       "202311    3/27/2018  Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...   \n",
       "202312    3/27/2018  Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...   \n",
       "202313    3/27/2018  Peak Service (Weekdays 6:30-9:30AM, 3:30PM-6:3...   \n",
       "\n",
       "       ROUTE_TYPE  OTP_NUMERATOR  OTP_DENOMINATOR  % on time  PRCP  SNOW  \\\n",
       "202309        KBR            630              728   0.865385   0.0   0.0   \n",
       "202310        OTH            176              220   0.800000   0.0   0.0   \n",
       "202311        OTH            223              310   0.719355   0.0   0.0   \n",
       "202312        OTH            106              184   0.576087   0.0   0.0   \n",
       "202313        OTH             73               92   0.793478   0.0   0.0   \n",
       "\n",
       "        TAVG  TMAX  TMIN  \n",
       "202309  35.0  42.0  28.0  \n",
       "202310  35.0  42.0  28.0  \n",
       "202311  35.0  42.0  28.0  \n",
       "202312  35.0  42.0  28.0  \n",
       "202313  35.0  42.0  28.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw = bus.join(weath.set_index('DATE'), on ='SERVICE_DATE') #join datasets on dates\n",
    "#bw = bw.drop( columns = ['SERVICE_DATE','PEAK_OFFPEAK_IND']) # date no longer needed, may confuse algorithms\n",
    "bw.tail()\n",
    "#bw.to_csv(\"busWithWeather1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.to_csv(\"bw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in resulting data that's prepared for learning. Split data into training and test partitions after random re-ordering of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = pd.read_csv(\"bw_cleaned.csv\")\n",
    "#learn.info()\n",
    "\n",
    "learn = learn.sample(frac = 1)\n",
    "train_x = learn.iloc[0:120001,0:5]\n",
    "train_y = learn.iloc[0:120001,6]\n",
    "\n",
    "test_x = learn.iloc[120002:,0:5]\n",
    "test_y = learn.iloc[120002:,6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above data includes the \"peak or off peak hours\" attribute, the bottom does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = pd.read_csv(\"bw_nopeak.csv\")\n",
    "\n",
    "learn = learn.sample(frac = 1 )\n",
    "train_x = learn.iloc[0:120001,0:4]\n",
    "train_y = learn.iloc[0:120001,5]\n",
    "\n",
    "test_x = learn.iloc[120002:,0:4]\n",
    "test_y = learn.iloc[120002:,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor as mlp\n",
    "from sklearn.linear_model import TheilSenRegressor as TSR, SGDRegressor as SGD, LogisticRegression as LR\n",
    "from sklearn.svm import LinearSVR as LSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error as mae, r2_score as r2, explained_variance_score as evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :: mae: 2.435896, r2: 0.959362, evs: 0.960010\n",
      "testing :: mae: 2.424955, r2: 0.959711, evs: 0.960369\n"
     ]
    }
   ],
   "source": [
    "## FOR MULITLAYER PERCEPTRON NEURAL NETWORK\n",
    "mlpr = mlp()\n",
    "mlpr.fit(train_x,train_y)\n",
    "training_mae = mae(train_y, mlpr.predict(train_x)) #best is 0\n",
    "training_r2 = r2(train_y, mlpr.predict(train_x)) #best 1, can be neg(opposite of helpful good)\n",
    "training_evs = evs(train_y, mlpr.predict(train_x)) #best is 1 , lower worse\n",
    "print(\"training :: mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (training_mae,training_r2,training_evs))\n",
    "\n",
    "#after having removed peak/off peak flag from data set training performance has gone up\n",
    "test_mae = mae(test_y, mlpr.predict(test_x))\n",
    "test_r2 = r2(test_y, mlpr.predict(test_x))\n",
    "test_evs = evs(test_y, mlpr.predict(test_x))\n",
    "print(\"testing :: mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (test_mae,test_r2,test_evs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 2.371573, r2: 0.958320, evs: 0.958571\n",
      "testing :: mae: 2.361883, r2: 0.958742, evs: 0.958989\n"
     ]
    }
   ],
   "source": [
    "## FOR THEILSENREGRESSOR \n",
    "tsr = TSR()\n",
    "tsr.fit(train_x,train_y)\n",
    "training_mae = mae(train_y, tsr.predict(train_x)) #best is 0\n",
    "training_r2 = r2(train_y, tsr.predict(train_x)) #best 1, can be neg(opposite of helpful good)\n",
    "training_evs = evs(train_y, tsr.predict(train_x)) #best is 1 , lower worse\n",
    "print(\"mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (training_mae,training_r2,training_evs))\n",
    "\n",
    "## Have a positive r2 value for this regressor, so it might be worth tuning\n",
    "\n",
    "test_mae = mae(test_y, tsr.predict(test_x))\n",
    "test_r2 = r2(test_y, tsr.predict(test_x))\n",
    "test_evs = evs(test_y, tsr.predict(test_x))\n",
    "print(\"testing :: mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (test_mae,test_r2,test_evs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 3.070260, r2: 0.934703, evs: 0.956831\n",
      "testing :: mae: 3.067188, r2: 0.935070, evs: 0.957273\n"
     ]
    }
   ],
   "source": [
    "## FOR STOCHASTIC GRADIENT DESCENT\n",
    "sgd = SGD(max_iter = 1000)\n",
    "sgd.fit(train_x,train_y)\n",
    "training_mae = mae(train_y, sgd.predict(train_x)) #best is 0\n",
    "training_r2 = r2(train_y, sgd.predict(train_x)) #best 1, can be neg(opposite of helpful good)\n",
    "training_evs = evs(train_y, sgd.predict(train_x)) #best is 1 , lower worse\n",
    "print(\"mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (training_mae,training_r2,training_evs))\n",
    "\n",
    "#did much worse than mlp. probably not useful\n",
    "test_mae = mae(test_y, sgd.predict(test_x))\n",
    "test_r2 = r2(test_y, sgd.predict(test_x))\n",
    "test_evs = evs(test_y, sgd.predict(test_x))\n",
    "print(\"testing :: mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (test_mae,test_r2,test_evs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 5.100791, r2: 0.826813, evs: 0.829544\n",
      "testing :: mae: 5.101414, r2: 0.826410, evs: 0.829181\n"
     ]
    }
   ],
   "source": [
    "## FOR LOGISTIC REGRESSION\n",
    "\n",
    "lr = LR()\n",
    "lr.fit(train_x,train_y)\n",
    "training_mae = mae(train_y, lr.predict(train_x)) #best is 0\n",
    "training_r2 = r2(train_y, lr.predict(train_x)) #best 1, can be neg(opposite of helpful good)\n",
    "training_evs = evs(train_y, lr.predict(train_x)) #best is 1 , lower worse\n",
    "print(\"mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (training_mae,training_r2,training_evs))\n",
    "\n",
    "test_mae = mae(test_y, lr.predict(test_x))\n",
    "test_r2 = r2(test_y, lr.predict(test_x))\n",
    "test_evs = evs(test_y, lr.predict(test_x))\n",
    "print(\"testing :: mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (test_mae,test_r2,test_evs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 14.797663, r2: -0.175069, evs: 0.019918\n",
      "testing :: mae: 14.771081, r2: -0.177553, evs: 0.020015\n"
     ]
    }
   ],
   "source": [
    "## FOR SVM\n",
    "svm = SVR(kernel = 'rbf',max_iter = 1000)\n",
    "svm.fit(train_x,train_y)\n",
    "training_mae = mae(train_y, svm.predict(train_x)) #best is 0\n",
    "training_r2 = r2(train_y, svm.predict(train_x)) #best 1, can be neg(opposite of helpful good)\n",
    "training_evs = evs(train_y, svm.predict(train_x)) #best is 1 , lower worse\n",
    "print(\"mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (training_mae,training_r2,training_evs))\n",
    "\n",
    "test_mae = mae(test_y, svm.predict(test_x)) ####this one has under performed with the new data, not going to be useful\n",
    "test_r2 = r2(test_y, svm.predict(test_x))\n",
    "test_evs = evs(test_y, svm.predict(test_x))\n",
    "print(\"testing :: mae: %0.6f, r2: %0.6f, evs: %0.6f\" % (test_mae,test_r2,test_evs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## others -> beta regression, nearest neighbors?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
